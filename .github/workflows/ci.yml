name: ci

on:
  pull_request:
    paths:
      - 'apps/web/**'
      - 'apps/api/**'
      - 'schemas/**'
      - 'infra/**'
      - '.github/workflows/**'
  push:
    branches: [main]
    paths:
      - 'apps/web/**'
      - 'apps/api/**'
      - 'schemas/**'
      - 'infra/**'
      - '.github/workflows/**'

# Cancel previous runs on same PR/branch to avoid piling up
concurrency:
  group: ci-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # Determine which parts changed to run only necessary jobs
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      web: ${{ steps.filter.outputs.web }}
      api: ${{ steps.filter.outputs.api }}
      schemas: ${{ steps.filter.outputs.schemas }}
      infra: ${{ steps.filter.outputs.infra }}
    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0
      - name: Paths Filter
        id: filter
        uses: dorny/paths-filter@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          filters: |
            web:
              - 'apps/web/**'
            api:
              - 'apps/api/**'
              - 'infra/**'
            schemas:
              - 'schemas/**'
            infra:
              - 'infra/**'
  validate-schemas:
    needs: changes
    name: Schemas - Validate RuleSpec Examples
    runs-on: ubuntu-latest
    if: needs.changes.outputs.schemas == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: 20
      - name: Validate RuleSpec Examples
        run: node schemas/validate-all-examples.js

  ci-web:
    needs: changes
    name: Web - Lint, Typecheck, Test
    runs-on: ubuntu-latest
    if: needs.changes.outputs.web == 'true'
    defaults:
      run:
        working-directory: apps/web
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: 20
          cache: pnpm
          cache-dependency-path: apps/web/pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install
      - name: Lint
        run: pnpm lint
      - name: Typecheck
        run: pnpm typecheck
      - name: Test with Coverage
        run: CI=true pnpm test:coverage

      - name: Upload Web Coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: apps/web/coverage/lcov.info
          flags: web
          name: web-coverage
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      # UI-05: Accessibility Testing
      - name: Run Accessibility Unit Tests (jest-axe)
        run: CI=true pnpm test:a11y

  ci-web-a11y:
    needs: changes
    name: Web - Accessibility Tests (E2E)
    runs-on: ubuntu-latest
    if: needs.changes.outputs.web == 'true'
    defaults:
      run:
        working-directory: apps/web
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9
      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: 20
          cache: pnpm
          cache-dependency-path: apps/web/pnpm-lock.yaml
      - name: Install dependencies
        run: pnpm install
      - name: Install Playwright Browsers
        run: pnpm exec playwright install --with-deps chromium
      - name: Build Next.js for E2E
        run: pnpm build
      - name: Run Playwright Accessibility Tests
        run: pnpm test:e2e e2e/accessibility.spec.ts
      - name: Upload Playwright Report
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-a11y-report-${{ github.run_number }}
          path: apps/web/playwright-report/
          retention-days: 7

  ci-api:
    needs: changes
    name: API - Build and Test
    runs-on: ubuntu-latest
    if: needs.changes.outputs.api == 'true'
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: meeple
          POSTGRES_PASSWORD: meeplepass
          POSTGRES_DB: meepleai_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      qdrant:
        image: qdrant/qdrant:v1.12.4
        ports:
          - 6333:6333
          - 6334:6334
    defaults:
      run:
        working-directory: apps/api
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      - name: Install PDF extraction dependencies
        run: sudo apt-get update && sudo apt-get install -y libgdiplus
      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: '9.0.x'
      - name: Restore
        run: dotnet restore
      - name: Build
        run: dotnet build
      - name: Verify Qdrant is ready
        run: |
          echo "Waiting for Qdrant to be ready..."
          for i in {1..30}; do
            if curl -f http://localhost:6333/healthz > /dev/null 2>&1; then
              echo "Qdrant is ready!"
              break
            fi
            echo "Attempt $i: Qdrant not ready yet, waiting..."
            sleep 2
          done
          curl -v http://localhost:6333/healthz || echo "Qdrant health check failed"
      - name: Test with Coverage
        env:
          CI: true
          OPENROUTER_API_KEY: test-key-for-ci
          QDRANT_URL: http://127.0.0.1:6333
          ConnectionStrings__Postgres: Host=127.0.0.1;Port=5432;Database=meepleai_test;Username=meeple;Password=meeplepass;Maximum Pool Size=100
          OTEL_EXPORTER_OTLP_ENDPOINT: http://localhost:4318
        run: |
          # Run only refactored tests with IAsyncLifetime cleanup (ISSUE-319) + OpenTelemetry tests (OPS-02)
          dotnet test \
            --filter "FullyQualifiedName~GameEndpointsTests|FullyQualifiedName~ApiEndpointIntegrationTests|FullyQualifiedName~LogsEndpointTests|FullyQualifiedName~PdfIngestEndpointsTests|FullyQualifiedName~PdfUploadEndpointsTests|FullyQualifiedName~RateLimitingIntegrationTests|FullyQualifiedName~RuleSpecHistoryIntegrationTests|FullyQualifiedName~OpenTelemetryIntegrationTests" \
            --logger "console;verbosity=normal" \
            -p:CollectCoverage=true \
            -p:CoverletOutputFormat=lcov \
            -p:CoverletOutput=./tests/Api.Tests/coverage/

      - name: Upload API Coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: apps/api/tests/Api.Tests/coverage/coverage.info
          flags: api
          name: api-coverage
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  validate-observability-configs:
    needs: changes
    name: Validate Prometheus & Alertmanager Configs
    runs-on: ubuntu-latest
    if: needs.changes.outputs.infra == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Validate Prometheus Rules
        run: |
          docker run --rm \
            -v ${{ github.workspace }}/infra:/etc/prometheus:ro \
            prom/prometheus:v3.7.0 \
            promtool check rules /etc/prometheus/prometheus-rules.yml

      - name: Validate Prometheus Config
        run: |
          docker run --rm \
            -v ${{ github.workspace }}/infra:/etc/prometheus:ro \
            prom/prometheus:v3.7.0 \
            promtool check config /etc/prometheus/prometheus.yml

      - name: Validate Alertmanager Config
        run: |
          docker run --rm \
            -v ${{ github.workspace }}/infra:/etc/alertmanager:ro \
            prom/alertmanager:v0.27.0 \
            amtool check-config /etc/alertmanager/alertmanager.yml

      - name: Validate Grafana Dashboards
        run: |
          for dashboard in infra/dashboards/*.json; do
            echo "Validating $dashboard..."
            jq empty "$dashboard" || exit 1
          done

  rag-evaluation:
    needs: changes
    name: AI-06 - RAG Offline Evaluation
    runs-on: ubuntu-latest
    if: needs.changes.outputs.api == 'true'
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: meeple
          POSTGRES_PASSWORD: meeplepass
          POSTGRES_DB: meepleai_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      qdrant:
        image: qdrant/qdrant:v1.12.4
        ports:
          - 6333:6333
          - 6334:6334
    defaults:
      run:
        working-directory: apps/api
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: '9.0.x'

      - name: Restore
        run: dotnet restore

      - name: Build
        run: dotnet build --no-restore

      - name: Verify Qdrant is ready
        run: |
          echo "Waiting for Qdrant to be ready..."
          for i in {1..30}; do
            if curl -f http://localhost:6333/healthz > /dev/null 2>&1; then
              echo "Qdrant is ready!"
              break
            fi
            echo "Attempt $i: Qdrant not ready yet, waiting..."
            sleep 2
          done
          curl -v http://localhost:6333/healthz || echo "Qdrant health check failed"

      - name: Run RAG Evaluation Tests
        env:
          CI: true
          QDRANT_URL: http://127.0.0.1:6333
          ConnectionStrings__Postgres: Host=127.0.0.1;Port=5432;Database=meepleai_test;Username=meeple;Password=meeplepass;Maximum Pool Size=100
        run: |
          # Run RAG evaluation integration tests
          dotnet test \
            --filter "FullyQualifiedName~RagEvaluationIntegrationTests" \
            --logger "console;verbosity=normal" \
            --no-build

      - name: Generate RAG Evaluation Report
        if: always()
        env:
          CI: true
          QDRANT_URL: http://127.0.0.1:6333
          ConnectionStrings__Postgres: Host=127.0.0.1;Port=5432;Database=meepleai_test;Username=meeple;Password=meeplepass;Maximum Pool Size=100
        run: |
          # Create output directory
          mkdir -p evaluation-reports

          # Run evaluation and capture output
          # Note: This requires a console app or test that outputs the report
          # For now, we rely on the integration tests which validate the evaluation logic
          echo "RAG evaluation completed. Check test results for metrics."

          # Create summary report
          cat > evaluation-reports/rag-evaluation-summary.md << 'EOF'
          # RAG Evaluation Summary

          **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Quality Thresholds

          - **Minimum Precision@5:** 0.70 (70%)
          - **Minimum Mean Reciprocal Rank (MRR):** 0.60 (60%)
          - **Maximum Latency p95:** 2000ms (2 seconds)
          - **Minimum Success Rate:** 0.95 (95%)

          ## Test Execution

          RAG evaluation integration tests have been executed.
          Review test output above for detailed metrics.

          ## Notes

          - Evaluation uses test dataset: `tests/Api.Tests/TestData/rag-evaluation-dataset.json`
          - Tests validate Precision@K, Recall@K, MRR, and latency percentiles
          - Quality gates enforce minimum performance standards

          For full evaluation report with per-query metrics, run locally:
          ```bash
          cd apps/api
          dotnet test --filter "FullyQualifiedName~RagEvaluationIntegrationTests" --logger "console;verbosity=detailed"
          ```
          EOF

      - name: Upload RAG Evaluation Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: rag-evaluation-report-${{ github.run_number }}
          path: apps/api/evaluation-reports/
          retention-days: 30

      - name: Check Quality Gates
        if: always()
        run: |
          echo "✓ RAG evaluation quality gates checked"
          echo "If tests passed, all quality thresholds were met:"
          echo "  - Precision@5 >= 0.70"
          echo "  - MRR >= 0.60"
          echo "  - Latency p95 <= 2000ms"
          echo "  - Success rate >= 95%"
